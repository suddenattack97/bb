"""
TCN ë² ì´ìŠ¤ ëª¨ë¸ ì´ˆê¸° í•™ìŠµ ìŠ¤í¬ë¦½íŠ¸
BTC_all_1m.csv ì—ì„œ í”¼ì²˜ë¥¼ ìƒì„±í•˜ê³  TCNForecasterë¥¼ í•™ìŠµí•©ë‹ˆë‹¤.
í•™ìŠµ ì™„ë£Œ í›„ tcn_base_model.pth ì™€ scaler.npy ê°€ ì €ì¥ë©ë‹ˆë‹¤.
ì´ ë‘ íŒŒì¼ì´ ìˆìœ¼ë©´ server.py ê¸°ë™ ì‹œ ìë™ìœ¼ë¡œ ë¡œë“œë©ë‹ˆë‹¤.
"""
import numpy as np
import torch
import torch.nn as nn
from torch.utils.data import Dataset, DataLoader

# model.py ì—ì„œ TCNForecaster ì„í¬íŠ¸
from model import TCNForecaster

try:
    import pandas as pd
    import pandas_ta as ta
except ImportError as e:
    raise SystemExit(
        f"pandas / pandas_ta ê°€ í•„ìš”í•©ë‹ˆë‹¤: {e}\n"
        "pip install pandas pandas_ta ë¥¼ ì‹¤í–‰í•˜ì„¸ìš”."
    )


class BigBinanceDataset(Dataset):
    def __init__(self, csv_file: str, seq_len: int = 60, pred_len: int = 5):
        print("ëŒ€ê·œëª¨ CSV íŒŒì¼ ë¡œë“œ ë° ì§€í‘œ ì—°ì‚° ì¤‘... (ì‹œê°„ì´ ë‹¤ì†Œ ì†Œìš”ë©ë‹ˆë‹¤)")
        df = pd.read_csv(csv_file, index_col='timestamp', parse_dates=True)

        # ì¤‘ë³µ ì œê±° ë° ì •ë ¬
        df = df[~df.index.duplicated(keep='first')].sort_index()

        # ìµœê·¼ 3ë…„ì¹˜ë§Œ ì‚¬ìš© (RAM ì ˆì•½)
        df = df.loc['2022-01-01':]

        # í”¼ì²˜ ì—”ì§€ë‹ˆì–´ë§
        df['log_return'] = np.log(df['close'] / df['close'].shift(1)).fillna(0)
        df['rsi_14']     = ta.rsi(df['close'], length=14).fillna(50)
        df['vwap']       = ta.vwap(df['high'], df['low'], df['close'], df['volume']).ffill().bfill()

        df = df.dropna()

        self.seq_len  = seq_len
        self.pred_len = pred_len

        features = ['log_return', 'rsi_14', 'vwap', 'volume']
        raw = df[features].values.astype(np.float32)

        # ì •ê·œí™” íŒŒë¼ë¯¸í„° ì €ì¥ (server.py ì—ì„œ ë™ì¼í•˜ê²Œ ì‚¬ìš©)
        self.mean = raw.mean(axis=0)
        self.std  = raw.std(axis=0) + 1e-8
        self.data_norm = (raw - self.mean) / self.std

        # íƒ€ê¹ƒ: log_return (ì¸ë±ìŠ¤ 0)
        self.data_raw  = raw
        self.target_idx = 0
        print(f"ë°ì´í„°ì…‹ ì¤€ë¹„ ì™„ë£Œ: {len(self)} ìƒ˜í”Œ")

    def __len__(self) -> int:
        return len(self.data_norm) - self.seq_len - self.pred_len

    def __getitem__(self, idx: int):
        x = self.data_norm[idx : idx + self.seq_len]
        y = self.data_raw[idx + self.seq_len : idx + self.seq_len + self.pred_len, self.target_idx]
        return torch.tensor(x), torch.tensor(y)


def train_base_model(csv_file: str = "BTC_all_1m.csv", epochs: int = 5):
    dataset     = BigBinanceDataset(csv_file)
    train_loader = DataLoader(dataset, batch_size=1024, shuffle=True, num_workers=0)

    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    print(f"í•™ìŠµ ë””ë°”ì´ìŠ¤: {device}")

    model     = TCNForecaster(num_features=4, output_steps=5).to(device)
    optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)
    criterion = nn.MSELoss()

    for epoch in range(epochs):
        model.train()
        total_loss = 0.0
        for i, (x, y) in enumerate(train_loader):
            x, y = x.to(device), y.to(device)
            optimizer.zero_grad()
            loss = criterion(model(x), y)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()

            if i % 500 == 0:
                print(f"  Epoch [{epoch+1}/{epochs}] Step [{i}/{len(train_loader)}] "
                      f"Loss: {loss.item():.6f}")

        avg = total_loss / len(train_loader)
        print(f"âœ… Epoch {epoch+1}/{epochs} ì™„ë£Œ â€” í‰ê·  Loss: {avg:.6f}")

    torch.save(model.state_dict(), "tcn_base_model.pth")
    np.save("scaler.npy", {'mean': dataset.mean, 'std': dataset.std})
    print("ğŸ‰ ì´ˆê¸° ë² ì´ìŠ¤ ëª¨ë¸ í•™ìŠµ ë° ì €ì¥ ì™„ë£Œ! (tcn_base_model.pth, scaler.npy)")


if __name__ == "__main__":
    train_base_model()
